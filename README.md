# 机器学习(Machine Learning)
- 监督学习(Supervised Learning)：训练样本带有信息标记(**y值**)，利用已有的训练样本信息学习数据的规律预测未知的新样本标签。
  - 回归分析(Regression)
  - 分类(Classification)
- 无监督学习(Unsupervised Learning)：训练样本的标记信息时未知的，目测是为了揭露训练样本的内在数学，结构和信息，为进一步的数据挖掘提供基础。
  - 聚类(Clustering)
## 回归
- 

## 分类算法
- 一种对**离散型随机变量**建模或预测的监督学习算法。
- 使用案例包括邮件过滤、金融欺诈和预测雇员异动等输出为类别的任务。
- 分类算法通常适用于预测一个类别(或类别的概率)而不是连续的数值。

### (基础)决策树 Decision Tree
决策树是一个树结构(可以是二叉树或非二叉树)。

其每个非叶节点表示一个**特征属性**上的测试，每个分支代表这个特征属性在某个值域上的输出，而每个叶节点存放一个类别。

使用决策树进行决策的过程就是从**根节点开始**,测试待分类项中相应的特征属性，并按照其值选择输出分支，知道到达叶子节点，将**叶子节点**存放的类别作为决策结果。

**优点：**
- 适用任何类型的数据(类别变量更普遍)
- 直观、决策树可以提供可视化，便于理解
- 模型预测出的结果简单，可解释性强
- 适用于小规模数据

**缺点：**
- 当数据中存在连续变量的属性时，决策树表现并不是很好
- 不稳定性，一点点的扰动或者改动都可能改动整棵树
- 特殊属性增加时，错误增加的比较快
- 很容易在训练数据中生成复杂的树结构，造成过拟合。

### 随机森林 Random Forest
![image](https://github.com/teamowu/Machine-Learning/blob/master/images/Random%20Forest.png)

**优点：**
- 随机森林不容易限于过拟合
- 具有很好的抗噪声能力
- 处理很高维度(feature多)的数据，并且不用做特征选择
- 训练速度快

## 聚类
物以类聚，人以群分
- 一种无监督式机器学习(即**数据没有标注**)
- 算法基于数据的内部结构寻找观察样本的自然族群(即集群)
- 使用案例包括客户细分，新闻聚类，文章推荐等等。

**用于衡量相似性的两个指标**：
- 欧式距离 Euclidean distance 
- 曼哈顿距离 Manhattan distance
- 余弦相似性 cosine
- Jaccard系数

## 降维

## 离群值检测
